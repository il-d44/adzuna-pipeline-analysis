import streamlit as st
import seaborn as sns
import pandas as pd
import pydeck as pdk
import os
import sys
import plotly.graph_objects as go 
from wordcloud import WordCloud
from PIL import ImageFont

# Append path to recognise analysis module, as python won't recognise without
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
# Import user-made analysis functions 
from analysis import description_analysis as da
# Import list of technologies
from analysis.resources.technologies import tech
# Import list of professional skills
from analysis.resources.non_tech_skills import non_tech_skills

# Store CSV path
data_engineering_csv ="cleaned_data.csv"

# Load data from CSV
data_engineer_df = pd.read_csv(data_engineering_csv)




# Process description data for word analysis
processed_descriptions = da.process_data_frame(data_engineer_df)

# Call function to count most common techs in processed description data
tech_count = da.multi_count_word_category(processed_descriptions, tech)
# Count professional skills
skill_count = da.multi_count_word_category(processed_descriptions, non_tech_skills)




# Set constants for theme colour
adzuna_green_RGBA = [46, 125, 50, 140] # Adzuna green RGBA
adzuna_green = "#2e7d32" #Adzuna green


# --------------------------
# Begin App Content
# --------------------------

# Sidebar title
st.sidebar.title("Navigation")

# Sidebar options
page = st.sidebar.radio("Go to", ["Home", "Skills Trends", "Salary & Location Insights", "Raw Data"])


# Display image in the sidebar
st.sidebar.image("app/app_images/adzuna_logo.jpg", use_container_width=True)

# Add "Powered by Adzuna" text with some styling
st.sidebar.markdown(
    '<p style="text-align: center; font-size: 14px; color: #999;">Powered by <strong>Adzuna</strong></p>',
    unsafe_allow_html=True
)
# Display different content based on the selected page
if page == "Home":
    st.title("Data Engineering Job Analysis")
    st.markdown(
        """
        Welcome to the **Data Engineering Job    Analysis** dashboard!  
        Job searching can be an overwhelming process... This project is designed to give budding data engineers the insight they need to make the right decisions, with analysis of real-world job listings.  
        
        ### **What You Can Explore:**
        - **ðŸ’» Tech Trends** â€“ See which programming languages & tools are in demand.
        - **ðŸ’° Salary Insights** â€“ Understand salary distributions across locations.
        - **ðŸ“„ Raw Data** â€“ See the full dataset used in this analysis.
        
        _All data is sourced from **Adzuna**, a leading job search engine._
        """,

        unsafe_allow_html=True
    )

    # Queries for stats section
    total_job_listings = data_engineer_df['id'].nunique()
    avg_salary = round(data_engineer_df['salary_min'].mean())
    most_common_tech = max(tech_count, key=tech_count.get) # Return highest counted tech in tech count dictionary


    # Key Stats Section
    col1, col2, col3 = st.columns(3)
    col1.metric("Total Job Listings", total_job_listings)
    col2.metric("Avg. Salary", f"Â£{avg_salary}")
    col3.metric("Top Tech", most_common_tech)


    # Call to Action
    st.markdown(
        """
        ---
        **Use the sidebar to explore more insights!** 
        """,
        unsafe_allow_html=True
    )



elif page == "Skills Trends":
    st.title("Skills Trends ðŸ“ˆ")
    st.markdown("""
    ### Here we analyze the most in-demand Data Engineer skills. 
    - What technical experience is most sought after right now? 
    - Which professional skills are most valued?
    """)

    wordcloud_tabs = st.tabs(["Technologies", "Professional Skills"])

    # --------------------------
    # Tab: Technologies analysis
    # --------------------------
    with wordcloud_tabs[0]:
        # Add a title and description for the tech word cloud
        st.subheader("Most In-Demand Technologies")


        # --------------------------
        # Section: Word cloud of Technology count
        # --------------------------
        st.markdown("""
            This word cloud shows the most frequently mentioned **technologies** aggregated across job descriptions.  
        """)
        # world cloud not working on cloud
        # tech_word_cloud = da.test_wordcloud_image(processed_descriptions, tech)
        st.image("app/app_images/tech_wordcloud.png", use_container_width=True)  # Display tech word cloud

        st.markdown("""
            **Method**: The cloud is generated by counting words from job descriptions against a prebuilt list of the most common technologies.
            
            Stay ahead in the game by mastering these technologies!  
        """)

        # --------------------------
        # Section: Bar chart of Technology Counts
        # --------------------------
        st.markdown("#### Bar Chart Showing Most Frequent Technologies")

 
        
        # Sort data by frequency
        sorted_tech_count = dict(sorted(tech_count.items(), key=lambda item: item[1], reverse=True))

        # Extract sorted data for plotting
        names = list(sorted_tech_count.keys())
        frequencies = list(sorted_tech_count.values())

        # Create the bar chart
        fig = go.Figure(data=[go.Bar(
            x=names,
            y=frequencies,
            hoverinfo='x+y',
            marker=dict(color="#2e7d32")  # Adzuna green
        )])

        # Add title and labels
        fig.update_layout(
            title="",
            xaxis_title="Technology",
            yaxis_title="Frequency",
            template='plotly_dark'
        )

        # Show chart in Streamlit
        st.plotly_chart(fig, key="tech_chart")


    # --------------------------
    # Tab: Professional Skills Analysis
    # --------------------------
        
    with wordcloud_tabs[1]:

        # --------------------------
        # Section: Word Cloud of Most Frequent Professional Skills
        # --------------------------


        st.subheader("Most Valued Professional Skills")
        st.markdown("""
        This word cloud highlights the professional skills that are most valued by employers.
        Practice these skills and set yourself apart in a competitive job market!
        """)
        # world cloud not generating on cloud
        # skills_word_cloud = da.test_wordcloud_image(processed_descriptions, non_tech_skills)
        # use back up worldcloud from local file
        st.image("app/app_images/pro_skills_wordcloud.png", use_container_width=True)  

        
        
        # --------------------------
        # Section: Bar chart of Professional Skill Counts
        # --------------------------
        
        st.markdown("#### Bar Chart Showing Most Frequent Professional Skills")

        # Sort data by frequency
        sorted_pro_skills_count = dict(sorted(skill_count.items(), key=lambda item: item[1], reverse=True))

        # Extract sorted data for plotting
        names = list(sorted_pro_skills_count.keys())
        frequencies = list(sorted_pro_skills_count.values())

        # Create the bar chart
        fig = go.Figure(data=[go.Bar(
            x=names,
            y=frequencies,
            hoverinfo='x+y',
            marker=dict(color="#2e7d32")  # Adzuna green
        )])

        # Add title and labels
        fig.update_layout(
            title="",
            xaxis_title="Professional Skills",
            yaxis_title="Frequency",
            template='plotly_dark'
        )

        # Show chart in Streamlit
        st.plotly_chart(fig, key="pro_skills_chart")

        st.markdown(""" This bar chart shows the most frequently mentioned professional skills aggregated across Data Engineer job listings.""")



elif page == "Salary & Location Insights":
    st.title("Salary & Location Insights")
    st.write("Discover how salaries breakdown across data engineering jobs and how job locations are distributed across the UK.")

    tab1, tab2 = st.tabs(["Salaries", "Locations"])


    # --------------------------
    # Tab: Salary Distribution
    # --------------------------

    with tab1:
        # --------------------------
        # Section: Histogram of Distribution of Salaries
        # --------------------------
     


        # Prepare salary data
        salary_data = data_engineer_df['salary_min']

        # Create histogram
        fig = go.Figure(data=[go.Histogram(
            x=salary_data,
            nbinsx=40,
            marker_color=adzuna_green,
            hoverinfo='x+y'
        )])

        # Style the layout
        fig.update_layout(
            title="Salary Distribution for Data Engineer Roles",
            xaxis_title="Minimum Salary (Â£)",
            yaxis_title="Job Count",
            template='plotly_dark',
            bargap=0.05
        )

        # Display in Streamlit
        st.plotly_chart(fig)

        # Optional description
        st.write("This histogram shows the distribution of minimum salaries for Data Engineer roles, visualising where most listings tend to fall.")

        # --------------------------
        # Section: Map of Average Salaries by Location
        # --------------------------

        st.subheader("Average Salaries by Location")

        # Calculate the average minimum salary and count of listings by location
        salary_by_location = (
            data_engineer_df.groupby('location')
            .agg(
                salary_min_mean=('salary_min', 'mean'),
                lat=('lat', 'first'),
                lon=('lon', 'first'),
                job_count=('salary_min', 'count')
            )
            .reset_index()
        )
        # Round and format salary for tooltip
        salary_by_location['salary_label'] = salary_by_location['salary_min_mean'].round(0).astype(int).apply(lambda x: f"Â£{x:,}")

        # Set up the slider for minimum number of job listings
        min_jobs = st.slider(
            "Select minimum number of job listings per location:",
            min_value=1,
            max_value=int(salary_by_location['job_count'].max()),
            value=5,
            step=1
        )

        # Filter locations by minimum job count
        filtered_locations = salary_by_location[salary_by_location['job_count'] >= min_jobs]

        # Scale salary for circle size
        filtered_locations['scaled_salary'] = (
            filtered_locations['salary_min_mean'] / filtered_locations['salary_min_mean'].max() * 50000
        )


        # Map view centered on the UK
        map_view = pdk.ViewState(latitude=51.5074, longitude=-0.1278, zoom=5)

        # Define scatterplot layer
        layer = pdk.Layer(
            "ScatterplotLayer",
            data=filtered_locations,
            get_position='[lon, lat]',
            get_radius='scaled_salary',
            get_fill_color=adzuna_green_RGBA,
            pickable=True,
            auto_highlight=True,
        )

        # Tooltip using pre-formatted label
        tooltip = {
            "html": """
                <b>Location:</b> {location}<br>
                <b>Avg Min Salary:</b> {salary_label}<br>
                <b>Job Listings:</b> {job_count}
            """,
            "style": {"backgroundColor": "black", "color": "white"}
        }

        # Create deck
        deck = pdk.Deck(
            layers=[layer],
            initial_view_state=map_view,
            map_style="mapbox://styles/mapbox/dark-v10",
            tooltip=tooltip
        )

        # Map description
        st.markdown("#### Map of Average Minimum Salaries by Location ")


        # Render the map
        st.pydeck_chart(deck)

        st.write("""
                This interactive map visualises the average **minimum salaries** for Data Engineer roles across different UK locations.  
                Only locations with a **minimum number of job listings** (as set by the slider) are shown.  
                Each green circle represents a location â€” the **size** of the circle is proportional to the average minimum salary.  
                Hover over a location to see details including the **location name**, **average salary**, and **number of job listings**.
                """)

        # -------------------------
        # Bar chart for Salaries by Location
        # -------------------------

        st.subheader("Average Min Salaries by Location Filtered by Job Count")
        # Filter locations based on slider 
        filtered_bar_data = salary_by_location[salary_by_location['job_count'] >= min_jobs]

        # Sort by salary descending and take top N if needed
        bar_data = filtered_bar_data.sort_values(by='salary_min_mean', ascending=False).head(15)

        # Extract data for plotting
        locations = bar_data['location']
        salaries = bar_data['salary_min_mean']

        # Create custom hover text
        hover_text = [
        f"<b>{loc}</b><br>Avg Min Salary: Â£{int(sal):,}<br>Job Listings: {int(count)}"
        for loc, sal, count in zip(locations, salaries, bar_data['job_count'])
        ]

        # Create Plotly bar chart
        fig = go.Figure(data=[go.Bar(
        x=locations,
        y=salaries,
        name="",  # no trace label
        hovertext=hover_text,
        hoverinfo='text',  # only show custom hover text
        marker=dict(color="#2e7d32")
        )])

        # Update layout
        fig.update_layout(
            title="Average Minimum Salary by Location",
            xaxis_title="Location",
            yaxis_title="Salary (Â£)",
            template="plotly_dark",
            xaxis_tickangle=-45,
            margin=dict(t=50, b=100)
        )

        # Show chart in Streamlit
        st.plotly_chart(fig, use_container_width=True, key="salary_chart")

        # Description
        st.write("This figure show average **minimum salaries** for Data Engineer roles in bar chart form for more accurate comparison across locations. Use the above slider to filter minimum jobs listings for location displayed. ")


    # --------------------------
    # Tab: Location Distribution
    # --------------------------


    with tab2:

        # --------------------------
        # Section: Bar Chart for Job Location 
        # -------------------------

        # Get top 10 locations by job count
        location_counts = data_engineer_df['location'].value_counts().sort_values(ascending=False)
        top_locations = location_counts.head(10)

        # Create the bar chart using Plotly
        fig = go.Figure(data=[go.Bar(
            x=top_locations.index,
            y=top_locations.values,
            marker_color=adzuna_green,
            hoverinfo='x+y'
        )])

        # Update layout
        fig.update_layout(
            title="Top 10 U.K. Locations for Data Engineering Jobs",
            xaxis_title="Location",
            yaxis_title="Job Count",
            template='plotly_dark',
            xaxis_tickangle=45
        )

        # Display in Streamlit
        st.plotly_chart(fig)

        st.write("Bar chart showing the the most common cities where Data Engineer jobs are located according to listings.")

        st.markdown("<br><br>", unsafe_allow_html=True)  # Two lines of space


        # Calculate frequency of each location
        location_counts = (
            data_engineer_df.groupby(['lat', 'lon'])
            .agg(count=('lat', 'size'), location=('location', 'first'))
            .reset_index()
        )

        # Add a title above the map
        st.subheader(" Map of Data Engineer U.K. Locations")

        # View state centered on UK
        map_view = pdk.ViewState(latitude=51.5074, longitude=-0.1278, zoom=5)

        # Scatterplot layer
        layer = pdk.Layer(
            'ScatterplotLayer',
            location_counts,
            get_position='[lon, lat]',
            get_radius='count * 500',
            get_fill_color=adzuna_green_RGBA,
            pickable=True,
            auto_highlight=True,
        )

        # Tooltip
        tooltip = {
            "html": "<b>Location:</b> {location}<br><b>Frequency:</b> {count}",
            "style": {"backgroundColor": "black", "color": "white"}
        }

        # Deck
        deck = pdk.Deck(
            layers=[layer],
            initial_view_state=map_view,
            tooltip=tooltip,
            map_style="mapbox://styles/mapbox/dark-v10"
        )

        # Show map in Streamlit
        st.pydeck_chart(deck)

        st.write("This interactive map visualizes the distribution of Data Engineering job opportunities across the U.K. Each point represents a geographical location where these jobs are concentrated, with the size of the circles reflecting the frequency of job listings in that area.")


elif page == "Raw Data":
    st.title("Raw Data Exploration")
    st.write("Interact with the dataset directly!")
    # Display the full dataframe (this could be filtered based on user input)
    st.dataframe(data_engineer_df)






   